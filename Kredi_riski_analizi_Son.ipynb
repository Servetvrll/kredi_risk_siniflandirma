{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "18xBQxp7PHcoJj2PjwY-mbMAIhGbgeeEM",
      "authorship_tag": "ABX9TyOSLlYz5CbEI/JYMMFmI+Jg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Servetvrll/kredi_risk_siniflandirma/blob/main/Kredi_riski_analizi_Son.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# veri setine ilgili linkten ulaşabilirsiniz = https://www.kaggle.com/datasets/laotse/credit-risk-dataset\n",
        "# Veri setini Google Drive'dan Colab ortamına yüklüyoruz.\n",
        "# Eğer lokalde çalışıyorsanız, dosya yolunu güncelleyin.\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/credit_risk_dataset/credit_risk_dataset.csv\")\n",
        "\n",
        "\n",
        "# Veri setinin ilk 5 satırını göster\n",
        "print(data.head())\n",
        "print(\"---------------------\")\n",
        "\n",
        "# veri seti hakkında genel bilgileri (sütun tipleri,eksik değerler) gösterir\n",
        "print(data.info())\n",
        "print(\"---------------------\")\n",
        "\n",
        "# sayısal sütunlar için istatiksel özet verir\n",
        "print(data.describe())\n",
        "print(\"---------------------\")\n",
        "\n",
        "# Her sütundaki eksik değerlerin sayısını gösterir\n",
        "print(data.isnull().sum())\n",
        "print(\"---------------------\")\n"
      ],
      "metadata": {
        "id": "RJrC7OZIQal_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'person_emp_length' sütunundaki 30 yıldan yüksek değerlerin sayısını verir\n",
        "person_emp_aykirideger = (data[\"person_emp_length\"] > 30).sum()\n",
        "print(f\"'person_emp_length' sütununda 30 yıldan fazla çalışma süresine sahip {person_emp_aykirideger} kayıt var.\")\n",
        "print(\"---------------------\")\n",
        "\n",
        "# 'person_age' sütununda 80'den yüksek değerlerin sayısını ve değerleri verir\n",
        "print(\"'person_age' sütunundaki 80 yaşından büyük kayıtlar:\")\n",
        "print(data[data[\"person_age\"] > 80][\"person_age\"])\n",
        "print(\"---------------------\")\n",
        "\n",
        "# Anormal dereceden büyük olan (123 gibi) çalışma süreleri muhtemelen hatalı girilmiş.\n",
        "# Bunların yıllara çevrilmiş hatalı aylık veya başka bir birim olabileceği varsayarak\n",
        "# daha makul bir değere (örneğin 10 yıl) eşitlenmesi.\n",
        "data.loc[[0, 210], \"person_emp_length\"] = [10, 10]\n",
        "\n",
        "# 'person_age' sütunundaki 80 yaşından büyük aykırı değerleri kaldırma.\n",
        "# Bu değerler, gerçekçi olmayan yaşları temsil ettiğinden veri bütünlüğü için silinmiştir.\n",
        "data.drop(data[data[\"person_age\"] > 80].index, inplace=True)\n",
        "print(\"80 yaşından büyük kayıtlar silindikten sonraki sayısal özet:\")\n",
        "print(data.describe())\n",
        "print(\"---------------------\")"
      ],
      "metadata": {
        "id": "qSzTmPTGQnaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'person_emp_length' sütunundaki eksik değerleri medyan ile doldurma\n",
        "# Çalışma süresinin 0 ile 20 yıl arasında değiştiği göz önüne alındığında,\n",
        "# eksik değerlerin (muhtemelen çalışmama veya belirsizlik durumu) medyan ile doldurulması,\n",
        "# mevcut dağılımı koruyarak aykırı değerlerin etkisini azaltır.\n",
        "data[\"person_emp_length\"].fillna(data[\"person_emp_length\"].median(), inplace=True)\n",
        "\n",
        "# 'loan_int_rate' sütunundaki eksik değerleri 'loan_grade' gruplarına göre medyan ile doldurma\n",
        "# Faiz oranının kredi notu (loan_grade) ile ilişkili olduğu varsayımıyla,\n",
        "# her bir kredi notu grubundaki medyan faiz oranı ile doldurma daha mantıklı bir yaklaşım sunar.\n",
        "data['loan_int_rate'] = data.groupby('loan_grade')['loan_int_rate'].transform(\n",
        "    lambda x: x.fillna(x.median())\n",
        ")\n",
        "\n",
        "# Eksik değerlerin kalıp kalmadığını kontrol etme\n",
        "print(\"Eksik değer doldurulduktan sonraki durum:\")\n",
        "print(data.isnull().sum())\n",
        "print(\"---------------------\")"
      ],
      "metadata": {
        "id": "R7osY2lsQ6uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kategorik sütunlardaki her bir sınıfın dağılımını (sayısını) kontrol etme\n",
        "# Bu, kategorik özelliklerin dengesini ve her bir sınıfın veri setindeki temsilini anlamaya yardımcı olur.\n",
        "print(\"Kategori Sayıları - loan_grade:\")\n",
        "print(data['loan_grade'].value_counts())\n",
        "print(\"\\nKategori Sayıları - person_home_ownership:\")\n",
        "print(data['person_home_ownership'].value_counts())\n",
        "print(\"\\nKategori Sayıları - loan_intent:\")\n",
        "print(data['loan_intent'].value_counts())\n",
        "print(\"\\nKategori Sayıları - cb_person_default_on_file:\")\n",
        "print(data['cb_person_default_on_file'].value_counts())\n",
        "print(\"---------------------\")\n",
        "\n",
        "# Kategorik özellikleri sayısal formata dönüştürme (Label Encoding ve One-Hot Encoding)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Veri setindeki 'object' (kategorik) tipindeki sütunları seçme\n",
        "kategorik_sutunlar = data.select_dtypes(include=['object']).columns\n",
        "print(\"Dönüştürülecek Kategorik Sütunlar:\")\n",
        "print(kategorik_sutunlar)\n",
        "\n",
        "for col in kategorik_sutunlar:\n",
        "    if data[col].nunique() == 2:\n",
        "        # İki sınıfı olan kategorik sütunlar için Label Encoding (ikili dönüşüm)\n",
        "        # Örn: Yes / No -> 1 / 0 gibi değerler\n",
        "        le = LabelEncoder()\n",
        "        data[col] = le.fit_transform(data[col])\n",
        "    else:\n",
        "        # İkiden fazla sınıfı olan kategorik sütunlar için One-Hot Encoding\n",
        "        # Yeni sütunlar oluşturarak her bir sınıfı ikili (0 veya 1) olarak temsil eder.\n",
        "        # 'drop_first=False' ile tüm kategoriler tutulur.\n",
        "        data = pd.get_dummies(data, columns=[col], drop_first=False)\n",
        "\n",
        "print(\"\\nKategorik sütunlar dönüştürüldükten sonra veri setinin ilk 5 satırı:\")\n",
        "print(data.head())\n",
        "print(\"---------------------\")"
      ],
      "metadata": {
        "id": "SL5xaehxQ8ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sayısal sütunlardaki aykırı değerleri tespit etme ve görselleştirme\n",
        "numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
        "print(\"IQR Yöntemiyle Aykırı Değer Tespiti:\")\n",
        "\n",
        "for col in numerical_cols:\n",
        "    Q1 = data[col].quantile(0.25)\n",
        "    Q3 = data[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]\n",
        "    print(f\"{col}: {len(outliers)} aykırı değer\")\n",
        "print(\"---------------------\")\n",
        "\n",
        "# Her bir sayısal sütun için Boxplot görselleştirme (aykırı değerleri görmek için)\n",
        "print(\"Sayısal Sütunların Boxplot Görselleştirmesi:\")\n",
        "for col in numerical_cols:\n",
        "    plt.figure(figsize=(6, 1.5))\n",
        "    sns.boxplot(x=data[col])\n",
        "    plt.title(f\"{col} için Boxplot\")\n",
        "    plt.show()\n",
        "print(\"---------------------\")\n",
        "\n",
        "# Z-Skoru Yöntemiyle Aykırı Değer Tespiti\n",
        "from scipy.stats import zscore\n",
        "\n",
        "z_scores = data[numerical_cols].apply(zscore)\n",
        "outliers_zscore = (abs(z_scores) > 3).sum()\n",
        "print(\"Z-Skoru Yöntemiyle Aykırı Değer Sayıları (Z-skoru > 3):\")\n",
        "print(outliers_zscore)\n",
        "print(\"---------------------\")\n",
        "\n",
        "# Belirlenen sütunlardaki aykırı değerleri IQR yöntemine göre kırpma (clipping)\n",
        "# Bu yöntem, aykırı değerleri belirli bir alt ve üst sınıra çekerek modelin performansını artırabilir.\n",
        "clip_columns = [\n",
        "    'person_age', 'person_income', 'person_emp_length',\n",
        "    'loan_amnt', 'loan_int_rate', 'loan_percent_income',\n",
        "    'cb_person_cred_hist_length'\n",
        "]\n",
        "\n",
        "print(\"Aykırı Değerleri Kırpma İşlemi (IQR Yöntemiyle):\")\n",
        "for col in clip_columns:\n",
        "    Q1 = data[col].quantile(0.25)\n",
        "    Q3 = data[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    data[col] = data[col].clip(lower_bound, upper_bound)\n",
        "    print(f\"'{col}' sütunundaki aykırı değerler [{lower_bound:.2f}, {upper_bound:.2f}] aralığına kırpıldı.\")\n",
        "print(\"---------------------\")\n",
        "\n",
        "# Kırpma sonrası 'loan_status'a göre 'person_income' dağılımı görselleştirmesi\n",
        "print(\"'loan_status'a göre 'person_income' dağılımı (kırpma sonrası):\")\n",
        "sns.boxplot(x='loan_status', y='person_income', data=data)\n",
        "plt.title(\"Kredi Durumuna Göre Gelir Dağılımı (Aykırı Değerler Kırpıldıktan Sonra)\")\n",
        "plt.show()\n",
        "print(\"---------------------\")"
      ],
      "metadata": {
        "id": "PTYhh5G2Q9aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# StandardScaler, veriyi ortalaması 0 ve standart sapması 1 olacak şekilde dönüştürür.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Kırpılan sütunlar ölçeklendirme için de kullanıldı\n",
        "scale_columns = clip_columns\n",
        "\n",
        "# StandardScaler nesnesini başlat\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Belirlenen sütunlara standardizasyon uygulama\n",
        "data[scale_columns] = scaler.fit_transform(data[scale_columns])\n",
        "\n",
        "print(\"Standardizasyon Yapıldıktan Sonraki Veri Seti (İlk 5 Satır):\")\n",
        "print(data[scale_columns].head())\n",
        "print(\"---------------------\")\n",
        "\n",
        "# Ölçeklendirme ve diğer önişleme adımlarından sonra hedef değişken dağılımını tekrar kontrol etme\n",
        "sns.countplot(x='loan_status', data=data)\n",
        "plt.title(\"Kredi Durumlarının Dağılımı (Önişleme Sonrası)\")\n",
        "plt.xlabel(\"Kredi Durumu (0: Onaylandı, 1: Reddedildi)\")\n",
        "plt.ylabel(\"Sayı\")\n",
        "plt.show()\n",
        "print(\"---------------------\")\n",
        "\n",
        "# Önişleme sonrası özellikler arasındaki korelasyonu (ilişkiyi) gösteren ısı haritası\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.heatmap(data.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=.5)\n",
        "plt.title(\"Önişleme Sonrası Korelasyon Matrisi\")\n",
        "plt.show()\n",
        "print(\"---------------------\")"
      ],
      "metadata": {
        "id": "qeQfSWeEQ_pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# One-Hot Encoding sonrası oluşan 'bool' tipi sütunları int'e dönüştürme\n",
        "for col in data.select_dtypes('bool').columns:\n",
        "    data[col] = data[col].astype(int)\n",
        "\n",
        "print(\"Dönüştürülmüş Veri Setinin İlk 5 Satırı (Bool -> Int):\\n\")\n",
        "print(data.head())\n",
        "print(\"---------------------\")\n",
        "\n",
        "# Özellikleri (x) ve hedef değişkeni (y) ayırma\n",
        "x = data.drop(\"loan_status\", axis=1) # \"loan_status\" sütunu hedef değişkendir\n",
        "y = data[\"loan_status\"]\n",
        "\n",
        "# Eğitim ve test setlerine ayırma\n",
        "# test_size=0.2: Verinin %20'si test seti olarak ayrıldı\n",
        "# random_state=42: Bölme işleminin tekrarlanabilir olmasını sağlar\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Sınıf dengesizliğini gidermek için SMOTE uygulama\n",
        "# Hedef değişkendeki (loan_status) azınlık sınıfının örneklerini sentetik olarak artırır.\n",
        "# Bu modelin azınlık sınıfını daha iyi öğrenmesine yardımcı olur.\n",
        "smote = SMOTE(random_state=42)\n",
        "x_resampled, y_resampled = smote.fit_resample(x_train, y_train)\n",
        "\n",
        "print(\"SMOTE öncesi eğitim seti sınıf dağılımı:\")\n",
        "print(y_train.value_counts())\n",
        "print(\"\\nSMOTE sonrası eğitim seti sınıf dağılımı:\")\n",
        "print(pd.Series(y_resampled).value_counts())\n",
        "print(\"---------------------\")"
      ],
      "metadata": {
        "id": "6JLqqnQ1RBUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Kullanılacak modeller\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"XGBoost\": xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "print(\"Çapraz Doğrulama Sonuçları (F1 Skoru):\")\n",
        "for name, model in models.items():\n",
        "    # Her bir model için 5 katlı çapraz doğrulama uygula\n",
        "    # 'f1' scoring, dengesiz sınıflar için uygun bir metrik.\n",
        "    scores = cross_val_score(model, x_resampled, y_resampled, cv=5, scoring='f1', n_jobs=-1)\n",
        "    results[name] = scores\n",
        "    print(f\"{name} - F1 Ortalama Skoru: {scores.mean():.4f} | Standart Sapma: {scores.std():.4f}\")\n",
        "print(\"---------------------\")"
      ],
      "metadata": {
        "id": "EUpMYd5eRCow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, RocCurveDisplay\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "print(\"Seçilen Modellerin Test Seti Performansı:\\n\")\n",
        "\n",
        "# XGBoost Modelini Eğitme ve Değerlendirme\n",
        "print(\"---------- XGBoost Modeli ----------\")\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "xgb_model.fit(x_resampled, y_resampled)\n",
        "y_pred_xgb = xgb_model.predict(x_test)\n",
        "y_prob_xgb = xgb_model.predict_proba(x_test)[:, 1]\n",
        "\n",
        "print(\"XGBoost - Sınıflandırma Raporu:\")\n",
        "print(classification_report(y_test, y_pred_xgb))\n",
        "print(\"\\nXGBoost - Karmaşıklık Matrisi:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
        "print(\"---------------------\")\n",
        "\n",
        "# Random Forest Modelini Eğitme ve Değerlendirme\n",
        "print(\"---------- Random Forest Modeli ----------\")\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(x_resampled, y_resampled)\n",
        "y_pred_rf = rf_model.predict(x_test)\n",
        "y_prob_rf = rf_model.predict_proba(x_test)[:, 1]\n",
        "\n",
        "print(\"Random Forest - Sınıflandırma Raporu:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(\"\\nRandom Forest - Karmaşıklık Matrisi:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
        "print(\"---------------------\")\n",
        "\n",
        "# ROC AUC Skoru ve ROC Eğrisi Görselleştirmesi\n",
        "# ROC AUC: Modelin pozitif sınıfı doğru tahmin etme yeteneğinin bir ölçüsüdür.\n",
        "# ROC Eğrisi: Farklı sınıflandırma eşiklerinde True Positive Rate (TPR) ile False Positive Rate (FPR) arasındaki ilişkiyi gösterir.\n",
        "\n",
        "# ROC AUC Skorlarını Hesaplama\n",
        "auc_xgb = roc_auc_score(y_test, y_prob_xgb)\n",
        "auc_rf = roc_auc_score(y_test, y_prob_rf)\n",
        "\n",
        "print(f\"XGBoost ROC AUC: {auc_xgb:.4f}\")\n",
        "print(f\"Random Forest ROC AUC: {auc_rf:.4f}\")\n",
        "print(\"---------------------\")\n",
        "\n",
        "# ROC Eğrilerini Çizme ve Karşılaştırma\n",
        "print(\"ROC Eğrisi Karşılaştırması:\")\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# XGBoost için ROC eğrisi\n",
        "RocCurveDisplay.from_predictions(y_test, y_prob_xgb, name=\"XGBoost\", ax=plt.gca())\n",
        "\n",
        "# Random Forest için ROC eğrisi\n",
        "RocCurveDisplay.from_predictions(y_test, y_prob_rf, name=\"Random Forest\", ax=plt.gca())\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Rastgele Sınıflandırıcı\")\n",
        "plt.title(\"ROC Eğrisi Karşılaştırması\")\n",
        "plt.xlabel(\"Yanlış Pozitif Oranı (FPR)\")\n",
        "plt.ylabel(\"Doğru Pozitif Oranı (TPR)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(\"---------------------\")"
      ],
      "metadata": {
        "id": "vrWoS3BYRDvH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}